{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d467fe5f-14f5-481f-b1f5-c7d771c0570d",
   "metadata": {},
   "source": [
    "# Code to create training dataset for the vision model based on the previously collected data from the hand_signs_data_collection code.\n",
    "(usefule link: https://saturncloud.io/blog/how-to-write-text-in-jupyter-ipython-notebook/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e27355a7-60a5-47d5-97bf-e7af153eb4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "TRANSLATED_DATA_DIR = 'data_translated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb3140ee-87de-4ed3-9842-5ef5bd59ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.6, max_num_hands = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247d00f8-8905-4788-afd2-59d49b52e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = [], []\n",
    "for dir_ in os.listdir(DATA_DIR):\n",
    "    path = os.path.join(DATA_DIR, dir_)\n",
    "    translated_data_path = os.path.join(TRANSLATED_DATA_DIR, dir_)\n",
    "    if not os.path.exists(translated_data_path): os.makedirs(translated_data_path)\n",
    "        \n",
    "    for img_path in os.listdir(path):\n",
    "        data_aux, x_, y_ = [], [], []\n",
    "\n",
    "        img = cv2.imread(os.path.join(path, img_path))\n",
    "        # Flip image horizontally to correctly identify left hand being used in the collected images\n",
    "        #img = cv2.flip(img, 1)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(img_rgb)\n",
    "\n",
    "        # Only use the images with left hand for dataset generation => only 21 points for landmarks\n",
    "        if results.multi_hand_landmarks and results.multi_handedness[0].classification[0].label == 'Left':\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Write images with overlapped hand landmarks on the original data collected.\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    img,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS,  \n",
    "                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    mp_drawing_styles.get_default_hand_connections_style())\n",
    "                cv2.imwrite(os.path.join(translated_data_path, img_path), img)\n",
    "                \n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "    \n",
    "                    x_.append(x)\n",
    "                    y_.append(y)\n",
    "\n",
    "            # To reduce variability for different positions of the hand on the screen, each data point subtracts the lowest x and y position per frame.\n",
    "            # Essentially reducing the positions of all landmarks to be start at the bottom left conner of the image.\n",
    "            for i in range(len(hand_landmarks.landmark)):\n",
    "                x = hand_landmarks.landmark[i].x\n",
    "                y = hand_landmarks.landmark[i].y\n",
    "                data_aux.append([x - min(x_), y - min(y_)])\n",
    "\n",
    "            if data_aux:\n",
    "                data.append(data_aux)\n",
    "                labels.append(dir_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c18224d9-99dc-4a45-8da0-1395b693cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the data locally to be accessed by another code.\n",
    "f = open('data.p', 'wb')\n",
    "pickle.dump({'data': data, 'labels': labels}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb51da-35fc-4258-8081-56a528ce223f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
